== [[StateStoreCoordinator]] StateStoreCoordinator -- Tracking Locations of StateStores for StateStoreRDD

`StateStoreCoordinator` keeps track of link:spark-sql-streaming-StateStore.adoc[StateStores] loaded in Spark executors (across the nodes in a Spark cluster).

The main purpose of `StateStoreCoordinator` is for `StateStoreRDD` to link:spark-sql-streaming-StateStoreRDD.adoc#getPreferredLocations[get the location preferences for partitions] (based on the location of the stores).

[[instances]]
`StateStoreCoordinator` uses `instances` internal registry of link:spark-sql-streaming-StateStoreProvider.adoc[StateStoreProviders] by their ids and `ExecutorCacheTaskLocations`.

`StateStoreCoordinator` is a `ThreadSafeRpcEndpoint` RPC endpoint that manipulates <<instances, instances>> registry through <<messages, RPC messages>>.

[[messages]]
.StateStoreCoordinator RPC Endpoint's Messages and Message Handlers (in alphabetical order)
[width="100%",cols="1m,3",options="header"]
|===
| Message
| Message Handler

| DeactivateInstances
a| [[DeactivateInstances]] Removes <<spark-sql-streaming-StateStoreProviderId.adoc#, StateStoreProviderIds>> (from <<instances, instances>>) with `queryRunId` as `runId`

You should see the following DEBUG message in the logs:

```
Deactivating instances related to checkpoint location [runId]: [comma-separated storeIdsToRemove]
```

| GetLocation
a| [[GetLocation]] Gives the location of <<spark-sql-streaming-StateStoreProviderId.adoc#, StateStoreProviderId>> (from <<instances, instances>>) with the host and an executor id on that host.

You should see the following DEBUG message in the logs:

```
Got location of the state store [id]: [executorId]
```

| ReportActiveInstance
a| [[ReportActiveInstance]] Registers <<spark-sql-streaming-StateStoreProviderId.adoc#, StateStoreProviderId>> that is active on an executor (given host and port).

You should see the following DEBUG message in the logs:

```
Reported state store [id] is active at [executorId]
```

| StopCoordinator
a| [[StopCoordinator]] Stops `StateStoreCoordinator` RPC Endpoint

You should see the following DEBUG message in the logs:

```
StateStoreCoordinator stopped
```

| VerifyIfInstanceActive
a| [[VerifyIfInstanceActive]] Verifies if a given <<spark-sql-streaming-StateStoreProviderId.adoc#, StateStoreProviderId>> is registered (in <<instances, instances>>) on `executorId`

You should see the following DEBUG message in the logs:

```
Verified that state store [id] is active: [response]
```
|===

[[logging]]
[TIP]
====
Enable `INFO` or `DEBUG` logging level for `org.apache.spark.sql.execution.streaming.state.StateStoreCoordinator` to see what happens inside.

Add the following line to `conf/log4j.properties`:

```
log4j.logger.org.apache.spark.sql.execution.streaming.state.StateStoreCoordinator=TRACE
```

Refer to link:spark-sql-streaming-logging.adoc[Logging].
====
