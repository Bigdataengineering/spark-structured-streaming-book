== [[InputProcessor]] InputProcessor Helper Class of FlatMapGroupsWithStateExec Physical Operator

`InputProcessor` is a helper class to manage the state store of <<spark-sql-streaming-FlatMapGroupsWithStateExec.adoc#, FlatMapGroupsWithStateExec>> physical operator.

`InputProcessor` is <<creating-instance, created>> exclusively when `FlatMapGroupsWithStateExec` physical operator is <<spark-sql-streaming-FlatMapGroupsWithStateExec.adoc#doExecute, executed>> (and uses `InputProcessor` for the storeUpdateFunction while mapping over partitions with a state store).

[[creating-instance]][[store]]
`InputProcessor` takes a single <<spark-sql-streaming-StateStore.adoc#, StateStore>> to be created.

=== [[processNewData]] `processNewData` Method

[source, scala]
----
processNewData(dataIter: Iterator[InternalRow]): Iterator[InternalRow]
----

`processNewData`...FIXME

NOTE: `processNewData` is used exclusively when `FlatMapGroupsWithStateExec` physical operator is <<spark-sql-streaming-FlatMapGroupsWithStateExec.adoc#doExecute, executed>>.

=== [[processTimedOutState]] `processTimedOutState` Method

[source, scala]
----
processTimedOutState(): Iterator[InternalRow]
----

`processTimedOutState`...FIXME

NOTE: `processTimedOutState` is used exclusively when `FlatMapGroupsWithStateExec` physical operator is <<spark-sql-streaming-FlatMapGroupsWithStateExec.adoc#doExecute, executed>>.

=== [[callFunctionAndUpdateState]] `callFunctionAndUpdateState` Internal Method

[source, scala]
----
callFunctionAndUpdateState(
  stateData: StateData,
  valueRowIter: Iterator[InternalRow],
  hasTimedOut: Boolean): Iterator[InternalRow]
----

`callFunctionAndUpdateState` creates a key object by requesting the given `StateData` for the `UnsafeRow` of the key (_keyRow_) and converts it to an object (using the internal <<getKeyObj, state key converter>>).

`callFunctionAndUpdateState` creates value objects by taking every value row (from the given `valueRowIter` iterator) and converts them to objects (using the internal <<getValueObj, state value converter>>).

`callFunctionAndUpdateState` <<spark-sql-streaming-GroupStateImpl.adoc#createForStreaming, creates a new GroupStateImpl>> with the following:

* The current state value (of the given `StateData`) that could possibly be `null`

* The <<spark-sql-streaming-FlatMapGroupsWithStateExec.adoc#batchTimestampMs, batchTimestampMs>> of the parent `FlatMapGroupsWithStateExec` operator (that could possibly be <<spark-sql-streaming-GroupStateImpl.adoc#NO_TIMESTAMP, -1>>)

* The <<spark-sql-streaming-FlatMapGroupsWithStateExec.adoc#eventTimeWatermark, event-time watermark>> of the parent `FlatMapGroupsWithStateExec` operator (that could possibly be <<spark-sql-streaming-GroupStateImpl.adoc#NO_TIMESTAMP, -1>>)

* The <<spark-sql-streaming-FlatMapGroupsWithStateExec.adoc#timeoutConf, GroupStateTimeout>> of the parent `FlatMapGroupsWithStateExec` operator

* The <<spark-sql-streaming-FlatMapGroupsWithStateExec.adoc#watermarkPresent, watermarkPresent>> flag of the parent `FlatMapGroupsWithStateExec` operator

* The given `hasTimedOut` flag

`callFunctionAndUpdateState` then executes the <<spark-sql-streaming-FlatMapGroupsWithStateExec.adoc#func, user-defined state function>> (of the parent `FlatMapGroupsWithStateExec` operator) on the key object, value objects, and the newly-created `GroupStateImpl`.

For every output value from the user-defined state function, `callFunctionAndUpdateState` updates <<numOutputRows, numOutputRows>> performance metric and wraps the values to an internal row (using the internal <<getOutputRow, output value converter>>).

In the end, `callFunctionAndUpdateState` returns a `Iterator[InternalRow]` which calls the <<onIteratorCompletion, completion function>> right after rows have been processed (so the iterator is considered fully consumed).

NOTE: `callFunctionAndUpdateState` is used when `InputProcessor` is requested to <<processNewData, processNewData>> and <<processTimedOutState, processTimedOutState>>.

==== [[onIteratorCompletion]] "All Rows Processed" Callback -- `onIteratorCompletion` Internal Method

[source, scala]
----
onIteratorCompletion: Unit
----

`onIteratorCompletion` branches off per whether the `GroupStateImpl` has been marked <<spark-sql-streaming-GroupStateImpl.adoc#hasRemoved, removed>> and no <<spark-sql-streaming-GroupStateImpl.adoc#getTimeoutTimestamp, timeout timestamp>> is specified or not.

When the `GroupStateImpl` has been marked <<spark-sql-streaming-GroupStateImpl.adoc#hasRemoved, removed>> and no <<spark-sql-streaming-GroupStateImpl.adoc#getTimeoutTimestamp, timeout timestamp>> is specified, `onIteratorCompletion` does the following:

. Requests the <<spark-sql-streaming-FlatMapGroupsWithStateExec.adoc#stateManager, StateManager>> (of the parent `FlatMapGroupsWithStateExec` operator) to <<spark-sql-streaming-StateManager.adoc#removeState, remove the state>> (from the <<store, StateStore>> for the key row of the given `StateData`)

. Increments the <<numUpdatedStateRows, numUpdatedStateRows>> performance metric

Otherwise, when the `GroupStateImpl` has not been marked <<spark-sql-streaming-GroupStateImpl.adoc#hasRemoved, removed>> or the <<spark-sql-streaming-GroupStateImpl.adoc#getTimeoutTimestamp, timeout timestamp>> is specified, `onIteratorCompletion` checks whether the timeout timestamp has changed by comparing the timeout timestamps of the <<spark-sql-streaming-GroupStateImpl.adoc#getTimeoutTimestamp, GroupStateImpl>> and the given `StateData`.

(only when the `GroupStateImpl` has been <<spark-sql-streaming-GroupStateImpl.adoc#hasUpdated, updated>>, <<spark-sql-streaming-GroupStateImpl.adoc#hasRemoved, removed>> or the timeout timestamp changed) `onIteratorCompletion` does the following:

. Requests the <<spark-sql-streaming-FlatMapGroupsWithStateExec.adoc#stateManager, StateManager>> (of the parent `FlatMapGroupsWithStateExec` operator) to <<spark-sql-streaming-StateManager.adoc#putState, persist the state>> (in the <<store, StateStore>> with the key row, updated state object, and the timeout timestamp of the given `StateData`)

. Increments the <<numUpdatedStateRows, numUpdatedStateRows>> performance metrics

NOTE: `onIteratorCompletion` is used exclusively when `InputProcessor` is requested to <<callFunctionAndUpdateState, callFunctionAndUpdateState>> (right after rows have been processed)

=== [[internal-properties]] Internal Properties

[cols="30m,70",options="header",width="100%"]
|===
| Name
| Description

| getKeyObj
a| [[getKeyObj]] A *state key converter* (of type `InternalRow => Any`) to deserialize a given row (for a per-group state key) to the current state value

* The deserialization expression for keys is specified as the <<spark-sql-streaming-FlatMapGroupsWithStateExec.adoc#keyDeserializer, key deserializer expression>> when the parent `FlatMapGroupsWithStateExec` operator is created

* The data type of state keys is specified as the <<spark-sql-streaming-FlatMapGroupsWithStateExec.adoc#groupingAttributes, grouping attributes>> when the parent `FlatMapGroupsWithStateExec` operator is created

Used exclusively when `InputProcessor` is requested to <<callFunctionAndUpdateState, callFunctionAndUpdateState>>.

| getOutputRow
a| [[getOutputRow]] A *output value converter* (of type `Any => InternalRow`) to wrap a given output value (from the user-defined state function) to a row

* The data type of the row is specified as the data type of the <<spark-sql-streaming-FlatMapGroupsWithStateExec.adoc#outputObjAttr, output object attribute>> when the parent `FlatMapGroupsWithStateExec` operator is created

Used exclusively when `InputProcessor` is requested to <<callFunctionAndUpdateState, callFunctionAndUpdateState>>.

| getValueObj
a| [[getValueObj]] A *state value converter* (of type `InternalRow => Any`) to deserialize a given row (for a per-group state value) to the current state value

* The deserialization expression for value is specified as the <<spark-sql-streaming-FlatMapGroupsWithStateExec.adoc#valueDeserializer, value deserializer expression>> when the parent `FlatMapGroupsWithStateExec` operator is created

* The data type of state values is specified as the <<spark-sql-streaming-FlatMapGroupsWithStateExec.adoc#dataAttributes, data attributes>> when the parent `FlatMapGroupsWithStateExec` operator is created

Used exclusively when `InputProcessor` is requested to <<callFunctionAndUpdateState, callFunctionAndUpdateState>>.

| numOutputRows
a| [[numOutputRows]] `numOutputRows` performance metric

|===
