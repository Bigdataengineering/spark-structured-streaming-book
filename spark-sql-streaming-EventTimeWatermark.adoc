== [[EventTimeWatermark]] EventTimeWatermark Unary Logical Operator

`EventTimeWatermark` is a unary logical operator (`UnaryNode`) that is <<creating-instance, created>> as the result of <<spark-sql-streaming-Dataset-withWatermark.adoc#, Dataset.withWatermark>> operator.

[source, scala]
----
val rates = spark
  .readStream
  .format("rate")
  .load
  .withWatermark(eventTime = "timestamp", delayThreshold = "10 seconds") // <-- creates EventTimeWatermark logical operator
scala> rates.explain(extended = true)
== Parsed Logical Plan ==
'EventTimeWatermark 'timestamp, interval 10 seconds
+- StreamingRelationV2 org.apache.spark.sql.execution.streaming.sources.RateStreamProvider@2219ca9f, rate, [timestamp#693, value#694L]

== Analyzed Logical Plan ==
timestamp: timestamp, value: bigint
EventTimeWatermark timestamp#693: timestamp, interval 10 seconds
+- StreamingRelationV2 org.apache.spark.sql.execution.streaming.sources.RateStreamProvider@2219ca9f, rate, [timestamp#693, value#694L]

== Optimized Logical Plan ==
EventTimeWatermark timestamp#693: timestamp, interval 10 seconds
+- StreamingRelationV2 org.apache.spark.sql.execution.streaming.sources.RateStreamProvider@2219ca9f, rate, [timestamp#693, value#694L]

== Physical Plan ==
EventTimeWatermark timestamp#693: timestamp, interval 10 seconds
+- StreamingRelation rate, [timestamp#693, value#694L]
----

[[watermarkDelayMs]]
[[delayKey]]
`EventTimeWatermark` uses *spark.watermarkDelayMs* key (in the `Metadata` of the <<output, output attributes>>) to hold the event-time watermark delay (as a so-called _watermark attribute_ or _eventTime watermark_).

NOTE: The *event-time watermark delay* is used to calculate the difference between the event time of an event (that is modeled as a row in the Dataset for a streaming batch) and the time in the past.

[NOTE]
====
`EliminateEventTimeWatermark` logical optimization rule (i.e. `Rule[LogicalPlan]`) removes `EventTimeWatermark` logical operator from a logical plan if the <<child, child>> logical operator is not streaming, i.e. when <<spark-sql-streaming-Dataset-withWatermark.adoc#, Dataset.withWatermark>> operator is used on a batch query.

[source, scala]
----
val logs = spark.
  read. // <-- batch non-streaming query that makes `EliminateEventTimeWatermark` rule applicable
  format("text").
  load("logs")

// logs is a batch Dataset
assert(!logs.isStreaming)

val q = logs.
  withWatermark(eventTime = "timestamp", delayThreshold = "30 seconds") // <-- creates EventTimeWatermark
scala> println(q.queryExecution.logical.numberedTreeString) // <-- no EventTimeWatermark as it was removed immediately
00 Relation[value#0] text
----
====

`EventTimeWatermark` is converted (aka _planned_) to <<spark-sql-streaming-EventTimeWatermarkExec.adoc#, EventTimeWatermarkExec>> physical operator in <<spark-sql-streaming-StatefulAggregationStrategy.adoc#, StatefulAggregationStrategy>> execution planning strategy.

[[creating-instance]]
`EventTimeWatermark` takes the following to be created:

* [[eventTime]] Name of the column with event-time watermarks
* [[delay]] Delay (`CalendarInterval`)
* [[child]] Child logical operator (`LogicalPlan`)

=== [[output]] Output Schema -- `output` Property

[source, scala]
----
output: Seq[Attribute]
----

NOTE: `output` is part of the `QueryPlan` Contract to describe the attributes of (the schema of) the output.

`output` finds <<eventTime, eventTime>> column in the output schema of the <<child, child>> logical operator and updates the `Metadata` of the column with <<delayKey, spark.watermarkDelayMs>> key and the milliseconds for the delay.

`output` removes <<delayKey, spark.watermarkDelayMs>> key from the other columns.

[source, scala]
----
// See q created above
// FIXME How to access/show the eventTime column with the metadata updated to include spark.watermarkDelayMs?
import org.apache.spark.sql.catalyst.plans.logical.EventTimeWatermark
val etw = q.queryExecution.logical.asInstanceOf[EventTimeWatermark]
scala> etw.output.toStructType.printTreeString
root
 |-- timestamp: timestamp (nullable = true)
 |-- value: long (nullable = true)
----
