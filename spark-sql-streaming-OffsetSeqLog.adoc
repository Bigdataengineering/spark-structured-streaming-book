== [[OffsetSeqLog]] OffsetSeqLog -- HDFSMetadataLog for Offset Write-Ahead Log (WAL)

`OffsetSeqLog` is a <<spark-sql-streaming-HDFSMetadataLog.adoc#, HDFSMetadataLog>> with <<OffsetSeq, OffsetSeq>> metadata.

`OffsetSeqLog` is <<creating-instance, created>> exclusively for the <<spark-sql-streaming-StreamExecution.adoc#offsetLog, write-ahead log (WAL) of offsets>> of <<spark-sql-streaming-StreamExecution.adoc#, stream execution engines>> (i.e. <<spark-sql-streaming-ContinuousExecution.adoc#, ContinuousExecution>> and <<spark-sql-streaming-MicroBatchExecution.adoc#, MicroBatchExecution>>).

[[OffsetSeq]][[offsets]][[metadata]]
`OffsetSeqLog` uses <<spark-sql-streaming-OffsetSeq.adoc#, OffsetSeq>> for metadata which holds an ordered collection of zero or more offsets and optional metadata (as link:spark-sql-streaming-OffsetSeqMetadata.adoc[OffsetSeqMetadata] for keeping track of event time watermark as set up by a Spark developer and what was found in the records).

[[creating-instance]]
`OffsetSeqLog` (like the parent <<spark-sql-streaming-HDFSMetadataLog.adoc#creating-instance, HDFSMetadataLog>>) takes the following to be created:

* [[sparkSession]] `SparkSession`
* [[path]] Path of the metadata log directory

=== [[serialize]] Serializing Metadata (Writing Metadata in Serialized Format) -- `serialize` Method

[source, scala]
----
serialize(
  offsetSeq: OffsetSeq,
  out: OutputStream): Unit
----

NOTE: `serialize` is part of <<spark-sql-streaming-HDFSMetadataLog.adoc#serialize, HDFSMetadataLog Contract>> to serialize metadata (write metadata in serialized format).

`serialize` firstly writes out the version prefixed with `v` on a single line (e.g. `v1`) followed by the <<metadata, optional metadata>> in JSON format.

NOTE: The version in Spark 2.2 is *1* with the charset being *UTF-8*.

`serialize` then writes out the <<offsets, offsets>> in JSON format, one per line.

NOTE: No offsets to write in `offsetSeq` for a streaming source is marked as *-* (a dash) in the log.

```
$ ls -tr [checkpoint-directory]/offsets
0 1 2 3 4 5 6

$ cat [checkpoint-directory]/offsets/6
v1
{"batchWatermarkMs":0,"batchTimestampMs":1502872590006,"conf":{"spark.sql.shuffle.partitions":"200","spark.sql.streaming.stateStore.providerClass":"org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider"}}
51
```

=== [[deserialize]] Deserializing Metadata -- `deserialize` Method

[source, scala]
----
deserialize(in: InputStream): OffsetSeq
----

NOTE: `deserialize` is part of <<spark-sql-streaming-HDFSMetadataLog.adoc#deserialize, HDFSMetadataLog Contract>> to deserialize a metadata (from an `InputStream`).

`deserialize`...FIXME
