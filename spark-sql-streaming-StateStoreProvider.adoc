== [[StateStoreProvider]] StateStoreProvider Contract

`StateStoreProvider` is the <<contract, abstraction>> of <<implementations, state store providers>> that manage <<getStore, state data>> in stateful streaming queries.

NOTE: `StateStoreProvider` helper object uses <<spark-sql-streaming-properties.adoc#spark.sql.streaming.stateStore.providerClass, spark.sql.streaming.stateStore.providerClass>> internal configuration property for the name of the class of the <<implementations, StateStoreProvider implementation>>.

[[implementations]]
NOTE: <<spark-sql-streaming-HDFSBackedStateStoreProvider.adoc#, HDFSBackedStateStoreProvider>> is the only available implementation of the <<contract, StateStoreProvider Contract>> in Spark Structured Streaming.

[[contract]]
.StateStoreProvider Contract
[cols="30m,70",options="header",width="100%"]
|===
| Method
| Description

| close
a| [[close]]

[source, scala]
----
close(): Unit
----

Closes the state store provider

Used exclusively when `StateStore` helper object is requested to <<spark-sql-streaming-StateStore.adoc#unload, unload a state store provider>>

| doMaintenance
a| [[doMaintenance]]

[source, scala]
----
doMaintenance(): Unit = {}
----

Does maintenance if needed

Used exclusively when `StateStore` helper object is requested to <<spark-sql-streaming-StateStore.adoc#doMaintenance, perform maintenance of registered state store providers>>

| getStore
a| [[getStore]]

[source, scala]
----
getStore(version: Long): StateStore
----

Returns the <<spark-sql-streaming-StateStore.adoc#, StateStore>> for the specified version

Used exclusively when `StateStore` helper object is requested to <<spark-sql-streaming-StateStore.adoc#get-StateStore, get the StateStore for the given ID and version>>

| init
a| [[init]]

[source, scala]
----
init(
  stateStoreId: StateStoreId,
  keySchema: StructType,
  valueSchema: StructType,
  keyIndexOrdinal: Option[Int],
  storeConfs: StateStoreConf,
  hadoopConf: Configuration): Unit
----

Initializes the state store provider

Used exclusively when `StateStoreProvider` helper object is requested to <<createAndInit, create and initialize the StateStoreProvider>> for a given <<spark-sql-streaming-StateStoreId.adoc#, StateStoreId>> (when `StateStore` helper object is requested to <<spark-sql-streaming-StateStore.adoc#get-StateStore, retrieve a StateStore by ID and version>>)

| stateStoreId
a| [[stateStoreId]]

[source, scala]
----
stateStoreId: StateStoreId
----

Returns the <<spark-sql-streaming-StateStoreId.adoc#, StateStoreId>> (that was used at <<init, initialization>>)

Used when:

* `HDFSBackedStateStore` is requested for the <<spark-sql-streaming-HDFSBackedStateStore.adoc#id, unique id>>

* `HDFSBackedStateStoreProvider` is <<spark-sql-streaming-HDFSBackedStateStoreProvider.adoc#baseDir, created>> and requested for the <<spark-sql-streaming-HDFSBackedStateStoreProvider.adoc#toString, textual representation>>

| supportedCustomMetrics
a| [[supportedCustomMetrics]]

[source, scala]
----
supportedCustomMetrics: Seq[StateStoreCustomMetric]
----

<<spark-sql-streaming-StateStoreCustomMetric.adoc#, StateStoreCustomMetrics>> of the state store provider

Used when:

* `StateStoreWriter` stateful physical operators are requested for the <<spark-sql-streaming-StateStoreWriter.adoc#stateStoreCustomMetrics, stateStoreCustomMetrics>> (when requested for the <<spark-sql-streaming-StateStoreWriter.adoc#metrics, metrics>> and <<spark-sql-streaming-StateStoreWriter.adoc#getProgress, getProgress>>)

* `HDFSBackedStateStore` is requested for the <<spark-sql-streaming-HDFSBackedStateStore.adoc#metrics, metrics>>

|===

=== [[lifecycle]] Lifecycle of StateStoreProvider

The lifecycle of a `StateStoreProvider` starts when `StateStore` helper object (on a Spark executor) is requested for the <<spark-sql-streaming-StateStore.adoc#get-StateStore, StateStore by given provider ID and version>>.

NOTE: <<spark-sql-streaming-HDFSBackedStateStoreProvider.adoc#, HDFSBackedStateStoreProvider>> is the only available implementation of the <<contract, StateStoreProvider Contract>> in Spark Structured Streaming.

NOTE: Since `StateStore` and `StateStoreProvider` helper objects are Scala objects that gives that there can only be one instance of `StateStore` and `StateStoreProvider` on a JVM. That in turn means that there will be only one instance of each per JVM which is exactly the JVM of a Spark executor.

`StateStore` helper object requests `StateStoreProvider` helper object to <<createAndInit, createAndInit>> that creates the `StateStoreProvider` implementation (given <<spark-sql-streaming-properties.adoc#spark.sql.streaming.stateStore.providerClass, spark.sql.streaming.stateStore.providerClass>> internal configuration property) and requests it to <<init, initialize>>.

The initialized `StateStoreProvider` is cached in <<spark-sql-streaming-StateStore.adoc#loadedProviders, loadedProviders>> internal lookup table (for a <<spark-sql-streaming-StateStoreId.adoc#, StateStoreId>>) for later lookups.

`StateStoreProvider` helper object then requests the `StateStoreProvider` to <<getStore, getStore>> for the version.

An instance of `StateStoreProvider` is requested to <<doMaintenance, do its own maintenance>> or <<close, close>> (when <<verifyIfStoreInstanceActive, a corresponding StateStore is inactive>>) in <<MaintenanceTask, MaintenanceTask daemon thread>> that runs periodically every <<spark-sql-streaming-properties.adoc#spark.sql.streaming.stateStore.maintenanceInterval, spark.sql.streaming.stateStore.maintenanceInterval>> configuration property (default: `60s`).

=== [[createAndInit]] Creating and Initializing StateStoreProvider -- `createAndInit` Factory Method

[source, scala]
----
createAndInit(
  stateStoreId: StateStoreId,
  keySchema: StructType,
  valueSchema: StructType,
  indexOrdinal: Option[Int],
  storeConf: StateStoreConf,
  hadoopConf: Configuration): StateStoreProvider
----

`createAndInit` creates a new <<StateStoreProvider, StateStoreProvider>> (per <<spark-sql-streaming-properties.adoc#spark.sql.streaming.stateStore.providerClass, spark.sql.streaming.stateStore.providerClass>> internal configuration property).

`createAndInit` requests the `StateStoreProvider` to <<init, initialize>>.

NOTE: `createAndInit` is used exclusively when `StateStore` helper object is requested for the <<spark-sql-streaming-StateStore.adoc#get-StateStore, StateStore by given provider ID and version>>.
